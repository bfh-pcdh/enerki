export const ENV = {
                // BeeChat                              // LM Studio
    BASE_URL:   'https://inference.mlmp.ti.bfh.ch',    // 'http://localhost:1234',
    ENDPOINT:   '/api/chat/completions',                // '/v1/chat/completions',        
    MODEL:      'gpt-oss:120b',                         // 'openai/gpt-oss-20b',
    TOKEN:      ''   // 'not_needed_for_localhost' // insert your TOKEN here
}